# -YOLOv5s--Sign-language-recognition
基于改进 YOLOv5s 的手语识别算法
引言：随着科技的飞速发展，人工智能技术已广泛应用于各行各业，尤其在计算机视觉领域取得了显著进展。手语识别作为人工智能技术在特殊人群中的应用之一，正在逐渐成为社会关注的焦点。聋哑人群体在日常生活中面临着与他人沟通的巨大障碍，而手语作为其主要的交流方式，成为了他们表达思想和需求的重要手段。然而，由于手语识别的高复杂性和实时性要求，传统的基于图像处理或机器学习的方法在准确性、效率和可移植性方面仍面临诸多挑战。
近年来，深度学习技术，尤其是卷积神经网络(CNN)在图像识别领域取得了突破性进展，许多经典模型如 YOLO 系列、ResNet、VGG 等在目标检测和分类任务中取得了显著的成果。YOLOv5是一种高效的目标检测模型，具有较高的精度和速度，在众多应用中表现出色。然而，YOLOv5s模型由于其较大的模型体积和大量的参数，导致其在移动端设备上的应用受限，尤其是在计算资源较为有限的情况下，模型的实时处理性能大打折扣。因此，如何在保持模型精度的同时，降低模型的
计算复杂度，提升其在移动端的实时检测能力，成为了一个亟待解决的问题。为了应对这一挑战，本文提出了一种基于改进 YOLOv5s 的手语识别算法。针对 YOLOv5s模型在移动端应用中的不足，本文进行了两个方面的优化。首先，为了减少模型的计算量和存储需求采用了 MobilenetV3 作为主干网络结构，替换了 YOLOv5s中的骨干层。MobilenetV3 是一种轻量级的网络结构，在保持较高精度的同时，能够大幅减少计算量，非常适合在资源受限的设备上运行。其次，本文在 Neck 端引人了 EMA(Exponential Moving Average)注意力机制，以提升模型的特征提取能力，增强其在不同环境下的适应性。EMA 注意力机制通过对特征图的加权平均，能够使模
型更关注重要的特征区域，从而提高了检测的准确性和鲁棒性。为了验证所提方法的有效性，本文使用了 ASL(American SignLanguage)字母表数据集进行实验。该数据集包含了大量的手语图像，适用于手语识别任务。实验结果表明，改进后的 YOLOv5sMobilenetV3-EMA 模型在手语识别精度、检测速度和模型大小等方面均取得了显著提升。与原始YOLOv5s 模型相比，改进后的模型在移动端设备上能够实现更高的帧率，同时大幅减少了内存占用，具有更强的泛化能力和更好的实时性。这为手语识别在实际应用中的推广提供了可行的解决方案。
